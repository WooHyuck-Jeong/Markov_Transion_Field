{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "WARNING:tensorflow:From C:\\Users\\jwhyu\\AppData\\Local\\Temp/ipykernel_5492/3517717524.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__) \n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7468868182042614339\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6300696576\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4950795495204760934\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:0a:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from math import ceil\n",
    "from numba import njit, prange\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_array\n",
    "from pyts.preprocessing import MinMaxScaler\n",
    "from pyts.approximation import PiecewiseAggregateApproximation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Welding_data = np.load('E:/Result/ver.3.22/MTF/MTF.npz')\n",
    "\n",
    "X_data = Welding_data['X_data']\n",
    "y_data = Welding_data['y_data']\n",
    "i_data = Welding_data['i_data']\n",
    "\n",
    "Welding_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 ... 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test, i_train, i_test = train_test_split(X_data,y_data,i_data, test_size = 0.2, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 300, 300, 2)\n",
      "(943,)\n",
      "(236, 300, 300, 2)\n",
      "(236,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.concatenate((X_train,X_test))\n",
    "targets = np.concatenate((y_train,y_test))\n",
    "index = np.concatenate((i_train,i_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "targets = np_utils.to_categorical(targets)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, Input, Activation, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 300, 300, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 306, 306, 2)  0          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)            (None, 150, 150, 64  6272        ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalization)  (None, 150, 150, 64  256         ['conv1/conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)        (None, 150, 150, 64  0           ['conv1/bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 152, 152, 64  0          ['conv1/relu[0][0]']             \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 75, 75, 64)   0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 75, 75, 64)  256         ['pool1[0][0]']                  \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_0_relu (Activatio  (None, 75, 75, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 75, 75, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 75, 75, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 75, 75, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 75, 75, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Concatena  (None, 75, 75, 96)  0           ['pool1[0][0]',                  \n",
      " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_0_bn (BatchNormal  (None, 75, 75, 96)  384         ['conv2_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_0_relu (Activatio  (None, 75, 75, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 75, 75, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 75, 75, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 75, 75, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 75, 75, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Concatena  (None, 75, 75, 128)  0          ['conv2_block1_concat[0][0]',    \n",
      " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_0_bn (BatchNormal  (None, 75, 75, 128)  512        ['conv2_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_0_relu (Activatio  (None, 75, 75, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 75, 75, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 75, 75, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 75, 75, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 75, 75, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Concatena  (None, 75, 75, 160)  0          ['conv2_block2_concat[0][0]',    \n",
      " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_0_bn (BatchNormal  (None, 75, 75, 160)  640        ['conv2_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_0_relu (Activatio  (None, 75, 75, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_1_conv (Conv2D)   (None, 75, 75, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_1_bn (BatchNormal  (None, 75, 75, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_1_relu (Activatio  (None, 75, 75, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_2_conv (Conv2D)   (None, 75, 75, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Concatena  (None, 75, 75, 192)  0          ['conv2_block3_concat[0][0]',    \n",
      " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_0_bn (BatchNormal  (None, 75, 75, 192)  768        ['conv2_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_0_relu (Activatio  (None, 75, 75, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_1_conv (Conv2D)   (None, 75, 75, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_1_bn (BatchNormal  (None, 75, 75, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_1_relu (Activatio  (None, 75, 75, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_2_conv (Conv2D)   (None, 75, 75, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Concatena  (None, 75, 75, 224)  0          ['conv2_block4_concat[0][0]',    \n",
      " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_0_bn (BatchNormal  (None, 75, 75, 224)  896        ['conv2_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_0_relu (Activatio  (None, 75, 75, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_1_conv (Conv2D)   (None, 75, 75, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_1_bn (BatchNormal  (None, 75, 75, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_1_relu (Activatio  (None, 75, 75, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_2_conv (Conv2D)   (None, 75, 75, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Concatena  (None, 75, 75, 256)  0          ['conv2_block5_concat[0][0]',    \n",
      " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalization)  (None, 75, 75, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)        (None, 75, 75, 256)  0           ['pool2_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)            (None, 75, 75, 128)  32768       ['pool2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling2D)  (None, 37, 37, 128)  0           ['pool2_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 37, 37, 128)  512        ['pool2_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_0_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 37, 37, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 37, 37, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 37, 37, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Concatena  (None, 37, 37, 160)  0          ['pool2_pool[0][0]',             \n",
      " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_0_bn (BatchNormal  (None, 37, 37, 160)  640        ['conv3_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_0_relu (Activatio  (None, 37, 37, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 37, 37, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 37, 37, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 37, 37, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Concatena  (None, 37, 37, 192)  0          ['conv3_block1_concat[0][0]',    \n",
      " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_0_bn (BatchNormal  (None, 37, 37, 192)  768        ['conv3_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_0_relu (Activatio  (None, 37, 37, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 37, 37, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 37, 37, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 37, 37, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Concatena  (None, 37, 37, 224)  0          ['conv3_block2_concat[0][0]',    \n",
      " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_0_bn (BatchNormal  (None, 37, 37, 224)  896        ['conv3_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_0_relu (Activatio  (None, 37, 37, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 37, 37, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 37, 37, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 37, 37, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Concatena  (None, 37, 37, 256)  0          ['conv3_block3_concat[0][0]',    \n",
      " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_0_bn (BatchNormal  (None, 37, 37, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_0_relu (Activatio  (None, 37, 37, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2D)   (None, 37, 37, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNormal  (None, 37, 37, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2D)   (None, 37, 37, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Concatena  (None, 37, 37, 288)  0          ['conv3_block4_concat[0][0]',    \n",
      " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_0_bn (BatchNormal  (None, 37, 37, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_0_relu (Activatio  (None, 37, 37, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2D)   (None, 37, 37, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNormal  (None, 37, 37, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2D)   (None, 37, 37, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Concatena  (None, 37, 37, 320)  0          ['conv3_block5_concat[0][0]',    \n",
      " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_0_bn (BatchNormal  (None, 37, 37, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_0_relu (Activatio  (None, 37, 37, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2D)   (None, 37, 37, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNormal  (None, 37, 37, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2D)   (None, 37, 37, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Concatena  (None, 37, 37, 352)  0          ['conv3_block6_concat[0][0]',    \n",
      " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_0_bn (BatchNormal  (None, 37, 37, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_0_relu (Activatio  (None, 37, 37, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2D)   (None, 37, 37, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNormal  (None, 37, 37, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2D)   (None, 37, 37, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Concatena  (None, 37, 37, 384)  0          ['conv3_block7_concat[0][0]',    \n",
      " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_0_bn (BatchNormal  (None, 37, 37, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_0_relu (Activatio  (None, 37, 37, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_1_conv (Conv2D)   (None, 37, 37, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_1_bn (BatchNormal  (None, 37, 37, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_1_relu (Activatio  (None, 37, 37, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_2_conv (Conv2D)   (None, 37, 37, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Concatena  (None, 37, 37, 416)  0          ['conv3_block8_concat[0][0]',    \n",
      " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block10_0_bn (BatchNorma  (None, 37, 37, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_0_relu (Activati  (None, 37, 37, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_1_conv (Conv2D)  (None, 37, 37, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_1_bn (BatchNorma  (None, 37, 37, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_1_relu (Activati  (None, 37, 37, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_2_conv (Conv2D)  (None, 37, 37, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Concaten  (None, 37, 37, 448)  0          ['conv3_block9_concat[0][0]',    \n",
      " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_0_bn (BatchNorma  (None, 37, 37, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_0_relu (Activati  (None, 37, 37, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_1_conv (Conv2D)  (None, 37, 37, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_1_bn (BatchNorma  (None, 37, 37, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_1_relu (Activati  (None, 37, 37, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_2_conv (Conv2D)  (None, 37, 37, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Concaten  (None, 37, 37, 480)  0          ['conv3_block10_concat[0][0]',   \n",
      " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_0_bn (BatchNorma  (None, 37, 37, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_0_relu (Activati  (None, 37, 37, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_1_conv (Conv2D)  (None, 37, 37, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_1_bn (BatchNorma  (None, 37, 37, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_1_relu (Activati  (None, 37, 37, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_2_conv (Conv2D)  (None, 37, 37, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Concaten  (None, 37, 37, 512)  0          ['conv3_block11_concat[0][0]',   \n",
      " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalization)  (None, 37, 37, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)        (None, 37, 37, 512)  0           ['pool3_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)            (None, 37, 37, 256)  131072      ['pool3_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling2D)  (None, 18, 18, 256)  0           ['pool3_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 18, 18, 256)  1024       ['pool3_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_0_relu (Activatio  (None, 18, 18, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 18, 18, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 18, 18, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 18, 18, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 18, 18, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Concatena  (None, 18, 18, 288)  0          ['pool3_pool[0][0]',             \n",
      " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_0_bn (BatchNormal  (None, 18, 18, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_0_relu (Activatio  (None, 18, 18, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 18, 18, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 18, 18, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 18, 18, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 18, 18, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_concat (Concatena  (None, 18, 18, 320)  0          ['conv4_block1_concat[0][0]',    \n",
      " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_0_bn (BatchNormal  (None, 18, 18, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_0_relu (Activatio  (None, 18, 18, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 18, 18, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 18, 18, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 18, 18, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 18, 18, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Concatena  (None, 18, 18, 352)  0          ['conv4_block2_concat[0][0]',    \n",
      " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_0_bn (BatchNormal  (None, 18, 18, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_0_relu (Activatio  (None, 18, 18, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 18, 18, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 18, 18, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 18, 18, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 18, 18, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Concatena  (None, 18, 18, 384)  0          ['conv4_block3_concat[0][0]',    \n",
      " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_0_bn (BatchNormal  (None, 18, 18, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_0_relu (Activatio  (None, 18, 18, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 18, 18, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 18, 18, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 18, 18, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 18, 18, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Concatena  (None, 18, 18, 416)  0          ['conv4_block4_concat[0][0]',    \n",
      " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_0_bn (BatchNormal  (None, 18, 18, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_0_relu (Activatio  (None, 18, 18, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 18, 18, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 18, 18, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 18, 18, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 18, 18, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Concatena  (None, 18, 18, 448)  0          ['conv4_block5_concat[0][0]',    \n",
      " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_0_bn (BatchNormal  (None, 18, 18, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_0_relu (Activatio  (None, 18, 18, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 18, 18, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 18, 18, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 18, 18, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 18, 18, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Concatena  (None, 18, 18, 480)  0          ['conv4_block6_concat[0][0]',    \n",
      " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_0_bn (BatchNormal  (None, 18, 18, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_0_relu (Activatio  (None, 18, 18, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 18, 18, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 18, 18, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 18, 18, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 18, 18, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Concatena  (None, 18, 18, 512)  0          ['conv4_block7_concat[0][0]',    \n",
      " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_0_bn (BatchNormal  (None, 18, 18, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_0_relu (Activatio  (None, 18, 18, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 18, 18, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 18, 18, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 18, 18, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 18, 18, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Concatena  (None, 18, 18, 544)  0          ['conv4_block8_concat[0][0]',    \n",
      " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_0_bn (BatchNorma  (None, 18, 18, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_0_relu (Activati  (None, 18, 18, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 18, 18, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Concaten  (None, 18, 18, 576)  0          ['conv4_block9_concat[0][0]',    \n",
      " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_0_bn (BatchNorma  (None, 18, 18, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_0_relu (Activati  (None, 18, 18, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 18, 18, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Concaten  (None, 18, 18, 608)  0          ['conv4_block10_concat[0][0]',   \n",
      " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_0_bn (BatchNorma  (None, 18, 18, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_0_relu (Activati  (None, 18, 18, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 18, 18, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Concaten  (None, 18, 18, 640)  0          ['conv4_block11_concat[0][0]',   \n",
      " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_0_bn (BatchNorma  (None, 18, 18, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_0_relu (Activati  (None, 18, 18, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 18, 18, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Concaten  (None, 18, 18, 672)  0          ['conv4_block12_concat[0][0]',   \n",
      " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_0_bn (BatchNorma  (None, 18, 18, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_0_relu (Activati  (None, 18, 18, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 18, 18, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Concaten  (None, 18, 18, 704)  0          ['conv4_block13_concat[0][0]',   \n",
      " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_0_bn (BatchNorma  (None, 18, 18, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_0_relu (Activati  (None, 18, 18, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 18, 18, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_concat (Concaten  (None, 18, 18, 736)  0          ['conv4_block14_concat[0][0]',   \n",
      " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_0_bn (BatchNorma  (None, 18, 18, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_0_relu (Activati  (None, 18, 18, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 18, 18, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Concaten  (None, 18, 18, 768)  0          ['conv4_block15_concat[0][0]',   \n",
      " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_0_bn (BatchNorma  (None, 18, 18, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_0_relu (Activati  (None, 18, 18, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 18, 18, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Concaten  (None, 18, 18, 800)  0          ['conv4_block16_concat[0][0]',   \n",
      " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_0_bn (BatchNorma  (None, 18, 18, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_0_relu (Activati  (None, 18, 18, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 18, 18, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Concaten  (None, 18, 18, 832)  0          ['conv4_block17_concat[0][0]',   \n",
      " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_0_bn (BatchNorma  (None, 18, 18, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_0_relu (Activati  (None, 18, 18, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 18, 18, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Concaten  (None, 18, 18, 864)  0          ['conv4_block18_concat[0][0]',   \n",
      " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_0_bn (BatchNorma  (None, 18, 18, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_0_relu (Activati  (None, 18, 18, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv2D)  (None, 18, 18, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Concaten  (None, 18, 18, 896)  0          ['conv4_block19_concat[0][0]',   \n",
      " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_0_bn (BatchNorma  (None, 18, 18, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_0_relu (Activati  (None, 18, 18, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 18, 18, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Concaten  (None, 18, 18, 928)  0          ['conv4_block20_concat[0][0]',   \n",
      " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_0_bn (BatchNorma  (None, 18, 18, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_0_relu (Activati  (None, 18, 18, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 18, 18, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Concaten  (None, 18, 18, 960)  0          ['conv4_block21_concat[0][0]',   \n",
      " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_0_bn (BatchNorma  (None, 18, 18, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_0_relu (Activati  (None, 18, 18, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 18, 18, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Concaten  (None, 18, 18, 992)  0          ['conv4_block22_concat[0][0]',   \n",
      " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_0_bn (BatchNorma  (None, 18, 18, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_0_relu (Activati  (None, 18, 18, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv2D)  (None, 18, 18, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchNorma  (None, 18, 18, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_1_relu (Activati  (None, 18, 18, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv2D)  (None, 18, 18, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Concaten  (None, 18, 18, 1024  0          ['conv4_block23_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalization)  (None, 18, 18, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)        (None, 18, 18, 1024  0           ['pool4_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool4_conv (Conv2D)            (None, 18, 18, 512)  524288      ['pool4_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling2D)  (None, 9, 9, 512)    0           ['pool4_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 9, 9, 512)   2048        ['pool4_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_0_relu (Activatio  (None, 9, 9, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 9, 9, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 9, 9, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 9, 9, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 9, 9, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Concatena  (None, 9, 9, 544)   0           ['pool4_pool[0][0]',             \n",
      " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_0_bn (BatchNormal  (None, 9, 9, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_0_relu (Activatio  (None, 9, 9, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 9, 9, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 9, 9, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 9, 9, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 9, 9, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Concatena  (None, 9, 9, 576)   0           ['conv5_block1_concat[0][0]',    \n",
      " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_0_bn (BatchNormal  (None, 9, 9, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_0_relu (Activatio  (None, 9, 9, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 9, 9, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 9, 9, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 9, 9, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 9, 9, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Concatena  (None, 9, 9, 608)   0           ['conv5_block2_concat[0][0]',    \n",
      " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_0_bn (BatchNormal  (None, 9, 9, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_0_relu (Activatio  (None, 9, 9, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_1_conv (Conv2D)   (None, 9, 9, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_1_bn (BatchNormal  (None, 9, 9, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_1_relu (Activatio  (None, 9, 9, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_2_conv (Conv2D)   (None, 9, 9, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Concatena  (None, 9, 9, 640)   0           ['conv5_block3_concat[0][0]',    \n",
      " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_0_bn (BatchNormal  (None, 9, 9, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_0_relu (Activatio  (None, 9, 9, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_1_conv (Conv2D)   (None, 9, 9, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_1_bn (BatchNormal  (None, 9, 9, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_1_relu (Activatio  (None, 9, 9, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_2_conv (Conv2D)   (None, 9, 9, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Concatena  (None, 9, 9, 672)   0           ['conv5_block4_concat[0][0]',    \n",
      " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_0_bn (BatchNormal  (None, 9, 9, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_0_relu (Activatio  (None, 9, 9, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_1_conv (Conv2D)   (None, 9, 9, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_1_bn (BatchNormal  (None, 9, 9, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_1_relu (Activatio  (None, 9, 9, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_2_conv (Conv2D)   (None, 9, 9, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Concatena  (None, 9, 9, 704)   0           ['conv5_block5_concat[0][0]',    \n",
      " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_0_bn (BatchNormal  (None, 9, 9, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_0_relu (Activatio  (None, 9, 9, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_1_conv (Conv2D)   (None, 9, 9, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_1_bn (BatchNormal  (None, 9, 9, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_1_relu (Activatio  (None, 9, 9, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_2_conv (Conv2D)   (None, 9, 9, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Concatena  (None, 9, 9, 736)   0           ['conv5_block6_concat[0][0]',    \n",
      " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_0_bn (BatchNormal  (None, 9, 9, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_0_relu (Activatio  (None, 9, 9, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_1_conv (Conv2D)   (None, 9, 9, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_1_bn (BatchNormal  (None, 9, 9, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_1_relu (Activatio  (None, 9, 9, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_2_conv (Conv2D)   (None, 9, 9, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Concatena  (None, 9, 9, 768)   0           ['conv5_block7_concat[0][0]',    \n",
      " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_0_bn (BatchNormal  (None, 9, 9, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_0_relu (Activatio  (None, 9, 9, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_1_conv (Conv2D)   (None, 9, 9, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_1_bn (BatchNormal  (None, 9, 9, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_1_relu (Activatio  (None, 9, 9, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_2_conv (Conv2D)   (None, 9, 9, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Concatena  (None, 9, 9, 800)   0           ['conv5_block8_concat[0][0]',    \n",
      " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block10_0_bn (BatchNorma  (None, 9, 9, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_0_relu (Activati  (None, 9, 9, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_1_conv (Conv2D)  (None, 9, 9, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_1_bn (BatchNorma  (None, 9, 9, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_1_relu (Activati  (None, 9, 9, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_2_conv (Conv2D)  (None, 9, 9, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Concaten  (None, 9, 9, 832)   0           ['conv5_block9_concat[0][0]',    \n",
      " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_0_bn (BatchNorma  (None, 9, 9, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_0_relu (Activati  (None, 9, 9, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_1_conv (Conv2D)  (None, 9, 9, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_1_bn (BatchNorma  (None, 9, 9, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_1_relu (Activati  (None, 9, 9, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_2_conv (Conv2D)  (None, 9, 9, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Concaten  (None, 9, 9, 864)   0           ['conv5_block10_concat[0][0]',   \n",
      " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_0_bn (BatchNorma  (None, 9, 9, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_0_relu (Activati  (None, 9, 9, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_1_conv (Conv2D)  (None, 9, 9, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_1_bn (BatchNorma  (None, 9, 9, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_1_relu (Activati  (None, 9, 9, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_2_conv (Conv2D)  (None, 9, 9, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Concaten  (None, 9, 9, 896)   0           ['conv5_block11_concat[0][0]',   \n",
      " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_0_bn (BatchNorma  (None, 9, 9, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_0_relu (Activati  (None, 9, 9, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_1_conv (Conv2D)  (None, 9, 9, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_1_bn (BatchNorma  (None, 9, 9, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_1_relu (Activati  (None, 9, 9, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_2_conv (Conv2D)  (None, 9, 9, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_concat (Concaten  (None, 9, 9, 928)   0           ['conv5_block12_concat[0][0]',   \n",
      " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_0_bn (BatchNorma  (None, 9, 9, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_0_relu (Activati  (None, 9, 9, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_1_conv (Conv2D)  (None, 9, 9, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_1_bn (BatchNorma  (None, 9, 9, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_1_relu (Activati  (None, 9, 9, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_2_conv (Conv2D)  (None, 9, 9, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Concaten  (None, 9, 9, 960)   0           ['conv5_block13_concat[0][0]',   \n",
      " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_0_bn (BatchNorma  (None, 9, 9, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_0_relu (Activati  (None, 9, 9, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_1_conv (Conv2D)  (None, 9, 9, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_1_bn (BatchNorma  (None, 9, 9, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_1_relu (Activati  (None, 9, 9, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_2_conv (Conv2D)  (None, 9, 9, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Concaten  (None, 9, 9, 992)   0           ['conv5_block14_concat[0][0]',   \n",
      " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_0_bn (BatchNorma  (None, 9, 9, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_0_relu (Activati  (None, 9, 9, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_1_conv (Conv2D)  (None, 9, 9, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_1_bn (BatchNorma  (None, 9, 9, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_1_relu (Activati  (None, 9, 9, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_2_conv (Conv2D)  (None, 9, 9, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Concaten  (None, 9, 9, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
      " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " bn (BatchNormalization)        (None, 9, 9, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
      "                                                                                                  \n",
      " relu (Activation)              (None, 9, 9, 1024)   0           ['bn[0][0]']                     \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 1024)        0           ['relu[0][0]']                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " softmax (Dense)                (None, 3)            3075        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,037,443\n",
      "Trainable params: 6,953,795\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(300, 300, 2))\n",
    "model = DenseNet121(input_tensor=input, include_top=False, weights=None, pooling='avg')\n",
    " \n",
    "x = model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(3, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(model.input, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class LearningRateSchedule(Callback):\n",
    "    def __init__(self, selected_epochs=[]):\n",
    "        self.selected_epochs = selected_epochs\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch+1) in self.selected_epochs:\n",
    "            lr = K.get_value(self.model.optimizer.lr)\n",
    "            K.set_value(self.model.optimizer.lr, lr*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  log   ()\n",
    "import datetime\n",
    "\n",
    "log_dir = \"logs/my_board/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "#    \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir= log_dir, histogram_freq= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "1061\n",
      "118\n",
      "1061\n",
      "118\n",
      "1061\n",
      "118\n",
      "1061\n",
      "118\n",
      "1061\n",
      "118\n",
      "1061\n",
      "118\n",
      "1061\n",
      "118\n",
      "1061\n",
      "118\n",
      "1061\n",
      "117\n",
      "1062\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "test = []\n",
    "train= []\n",
    "test_ = []\n",
    "train_ = []\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    print(len(test))\n",
    "    print(len(train))\n",
    "    for i in zip(test):\n",
    "        test_.append(i)\n",
    "    for i in zip(train):\n",
    "        train_.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_[0:1061]\n",
    "train = np.reshape(train, 1061)\n",
    "test = test_[0:117]\n",
    "test = np.reshape(test, 117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   9   17   34   40   46   53   54   83   97  101  109  113  128  140\n",
      "  141  146  168  171  179  186  204  228  253  263  264  280  306  316\n",
      "  358  372  374  377  379  389  412  422  431  432  446  449  459  463\n",
      "  467  473  484  492  508  509  510  513  523  551  564  571  597  602\n",
      "  620  631  632  642  663  665  666  685  698  716  724  729  732  734\n",
      "  756  761  771  793  797  804  815  819  831  836  840  841  879  883\n",
      "  884  890  907  912  915  920  936  941  946  955  963  975  982  983\n",
      "  985 1003 1013 1025 1047 1050 1053 1067 1070 1077 1083 1102 1105 1111\n",
      " 1120 1154 1166 1172 1177]\n",
      "[   0    1    2 ... 1174 1175 1176]\n",
      "['P_282' 'N_252' 'P_327' 'H_260' 'N_303' 'H_232' 'P_44' 'N_110' 'P_0'\n",
      " 'H_369' 'P_191' 'N_244' 'N_178' 'H_137' 'H_156' 'P_220' 'H_277' 'P_382'\n",
      " 'H_108' 'N_79' 'H_45' 'H_12' 'N_85' 'P_153' 'N_185' 'P_82' 'N_46' 'H_375'\n",
      " 'P_80' 'N_120' 'H_192' 'P_328' 'H_377' 'N_247' 'H_251' 'H_217' 'N_52'\n",
      " 'P_193' 'P_173' 'P_62' 'N_336' 'N_275' 'P_242' 'N_352' 'N_194' 'P_371'\n",
      " 'H_297' 'P_6' 'N_91' 'P_362' 'H_336' 'N_216' 'P_84' 'P_387' 'H_314'\n",
      " 'P_11' 'P_158' 'H_326' 'P_295' 'N_73' 'N_358' 'H_24' 'N_47' 'P_115'\n",
      " 'N_219' 'P_223' 'N_323' 'P_9' 'H_330' 'N_217' 'P_225' 'H_339' 'P_22'\n",
      " 'N_325' 'H_386' 'H_100' 'H_252' 'P_68' 'P_139' 'P_163' 'N_239' 'P_329'\n",
      " 'N_224' 'H_173' 'P_336' 'H_79' 'H_38' 'P_231' 'H_107' 'N_302' 'H_328'\n",
      " 'H_48' 'H_281' 'N_49' 'H_381' 'N_281' 'N_14' 'N_199' 'N_215' 'H_273'\n",
      " 'H_106' 'N_367' 'N_322' 'P_350' 'H_123' 'H_244' 'H_93' 'H_103' 'H_254'\n",
      " 'N_364' 'H_0' 'P_278' 'P_151' 'P_159' 'P_283' 'P_290' 'N_381']\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(train)\n",
    "print(index[test])\n",
    "print(targets[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.mkdir('E:/Result/ver.3.22/MTF/'+ 'weight_')\n",
    "os.mkdir('E:/Result/ver.3.22/MTF/'+ 'train_')\n",
    "os.mkdir('E:/Result/ver.3.22/MTF/'+ 'test_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(848,) (95,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwhyu\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 32s 311ms/step - loss: 0.3906 - accuracy: 0.7075 - val_loss: 0.7918 - val_accuracy: 0.3263\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 16s 227ms/step - loss: 0.2532 - accuracy: 0.8443 - val_loss: 1.5135 - val_accuracy: 0.3263\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 16s 226ms/step - loss: 0.2180 - accuracy: 0.8656 - val_loss: 1.5096 - val_accuracy: 0.3263\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.1792 - accuracy: 0.8903 - val_loss: 1.7025 - val_accuracy: 0.3263\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 16s 225ms/step - loss: 0.1510 - accuracy: 0.9210 - val_loss: 1.9210 - val_accuracy: 0.3263\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.1187 - accuracy: 0.9316 - val_loss: 3.0859 - val_accuracy: 0.3263\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 16s 226ms/step - loss: 0.1330 - accuracy: 0.9233 - val_loss: 0.5091 - val_accuracy: 0.7263\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.1026 - accuracy: 0.9575 - val_loss: 0.5385 - val_accuracy: 0.8211\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0976 - accuracy: 0.9446 - val_loss: 2.7544 - val_accuracy: 0.5053\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0461 - accuracy: 0.9788 - val_loss: 0.4189 - val_accuracy: 0.8211\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0617 - accuracy: 0.9741 - val_loss: 0.8395 - val_accuracy: 0.7263\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0516 - accuracy: 0.9764 - val_loss: 0.5968 - val_accuracy: 0.8211\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0448 - accuracy: 0.9741 - val_loss: 0.2898 - val_accuracy: 0.9158\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0639 - accuracy: 0.9658 - val_loss: 0.2829 - val_accuracy: 0.8526\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0433 - accuracy: 0.9811 - val_loss: 2.4011 - val_accuracy: 0.6316\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0333 - accuracy: 0.9823 - val_loss: 0.3591 - val_accuracy: 0.8842\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 16s 225ms/step - loss: 0.0353 - accuracy: 0.9847 - val_loss: 0.2918 - val_accuracy: 0.8947\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0344 - accuracy: 0.9870 - val_loss: 1.9500 - val_accuracy: 0.6737\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.6034 - val_accuracy: 0.8421\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0243 - accuracy: 0.9870 - val_loss: 0.5653 - val_accuracy: 0.8421\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 1.1007 - val_accuracy: 0.6842\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0227 - accuracy: 0.9894 - val_loss: 0.4654 - val_accuracy: 0.8316\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0319 - accuracy: 0.9835 - val_loss: 1.2474 - val_accuracy: 0.5684\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 16s 226ms/step - loss: 0.0185 - accuracy: 0.9929 - val_loss: 0.5643 - val_accuracy: 0.8316\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0208 - accuracy: 0.9906 - val_loss: 0.6833 - val_accuracy: 0.8316\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0148 - accuracy: 0.9941 - val_loss: 0.3790 - val_accuracy: 0.8842\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 16s 226ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.7703 - val_accuracy: 0.7579\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.2669 - val_accuracy: 0.8842\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 16s 225ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.7898 - val_accuracy: 0.8316\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.8639 - val_accuracy: 0.6737\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.4509 - val_accuracy: 0.8632\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.3287 - val_accuracy: 0.8842\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0188 - accuracy: 0.9929 - val_loss: 0.3438 - val_accuracy: 0.9158\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.4079 - val_accuracy: 0.8421\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.5646 - val_accuracy: 0.8526\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0128 - accuracy: 0.9941 - val_loss: 0.8865 - val_accuracy: 0.7789\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 16s 226ms/step - loss: 0.0146 - accuracy: 0.9941 - val_loss: 0.4750 - val_accuracy: 0.8211\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 16s 225ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.2847 - val_accuracy: 0.9053\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 16s 225ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8947\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0075 - accuracy: 0.9965 - val_loss: 0.3481 - val_accuracy: 0.8737\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0114 - accuracy: 0.9941 - val_loss: 0.4688 - val_accuracy: 0.8526\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 0.6513 - val_accuracy: 0.8105\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.3732 - val_accuracy: 0.8842\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 16s 220ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.4974 - val_accuracy: 0.8526\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8250 - val_accuracy: 0.8421\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0075 - accuracy: 0.9965 - val_loss: 0.3275 - val_accuracy: 0.9053\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.4401 - val_accuracy: 0.8632\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.3841 - val_accuracy: 0.8632\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.4279 - val_accuracy: 0.8737\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.3452 - val_accuracy: 0.8947\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4223 - val_accuracy: 0.8842\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4913 - val_accuracy: 0.8632\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 17s 231ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.8632\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 16s 227ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.4393 - val_accuracy: 0.8842\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 16s 228ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.4627 - val_accuracy: 0.8526\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9053\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.8947\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9053\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.8842\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0154 - accuracy: 0.9929 - val_loss: 1.0191 - val_accuracy: 0.8211\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.8737\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.8842\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.3347 - val_accuracy: 0.8842\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.3948 - val_accuracy: 0.8632\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.8842\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.4024 - val_accuracy: 0.8947\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9053\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.8737\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.8947\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4077 - val_accuracy: 0.8737\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.8947\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4078 - val_accuracy: 0.8842\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.8947\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5520 - val_accuracy: 0.8526\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 16s 225ms/step - loss: 0.0081 - accuracy: 0.9941 - val_loss: 0.5340 - val_accuracy: 0.8842\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.8842\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.8842\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.3724 - val_accuracy: 0.8842\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.8842\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.3372 - val_accuracy: 0.8947\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 16s 225ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.8842\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 16s 225ms/step - loss: 7.3266e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.8947\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 9.2759e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.8947\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 16s 226ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.8947\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 16s 228ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.3794 - val_accuracy: 0.8842\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 16s 224ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.8737\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.3481 - val_accuracy: 0.8737\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0071 - accuracy: 0.9953 - val_loss: 0.4595 - val_accuracy: 0.8947\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.8947\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.8947\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.3751 - val_accuracy: 0.8947\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.8947\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 16s 226ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.8947\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.3726 - val_accuracy: 0.8842\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.8947\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 16s 220ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.8947\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.8947\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 16s 221ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.8842\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.8842\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 8.2616e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.8947\n",
      "Score for fold 1: loss of 0.3676932752132416; accuracy of 89.47368264198303%\n",
      "(848,) (95,)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 22s 236ms/step - loss: 0.3735 - accuracy: 0.7559 - val_loss: 0.7542 - val_accuracy: 0.3263\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.2808 - accuracy: 0.8101 - val_loss: 1.1044 - val_accuracy: 0.3263\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.2056 - accuracy: 0.8703 - val_loss: 2.1141 - val_accuracy: 0.3263\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.1817 - accuracy: 0.8915 - val_loss: 3.9590 - val_accuracy: 0.3263\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.1456 - accuracy: 0.9198 - val_loss: 8.5170 - val_accuracy: 0.3263\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.1609 - accuracy: 0.9092 - val_loss: 1.1322 - val_accuracy: 0.3579\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.1034 - accuracy: 0.9493 - val_loss: 0.7927 - val_accuracy: 0.4316\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0911 - accuracy: 0.9469 - val_loss: 1.4818 - val_accuracy: 0.6105\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0894 - accuracy: 0.9493 - val_loss: 0.3197 - val_accuracy: 0.7684\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0820 - accuracy: 0.9517 - val_loss: 0.4578 - val_accuracy: 0.7895\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0670 - accuracy: 0.9693 - val_loss: 1.4515 - val_accuracy: 0.6526\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0647 - accuracy: 0.9587 - val_loss: 0.2274 - val_accuracy: 0.8526\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0389 - accuracy: 0.9800 - val_loss: 0.1839 - val_accuracy: 0.9158\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0768 - accuracy: 0.9611 - val_loss: 1.8075 - val_accuracy: 0.6526\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0601 - accuracy: 0.9682 - val_loss: 1.2434 - val_accuracy: 0.5684\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.3080 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0439 - accuracy: 0.9811 - val_loss: 0.7099 - val_accuracy: 0.6737\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0245 - accuracy: 0.9858 - val_loss: 0.6216 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.9005 - val_accuracy: 0.7895\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 16s 222ms/step - loss: 0.0272 - accuracy: 0.9870 - val_loss: 0.4035 - val_accuracy: 0.8632\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0229 - accuracy: 0.9917 - val_loss: 0.8449 - val_accuracy: 0.7158\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.3021 - val_accuracy: 0.8526\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.3964 - val_accuracy: 0.8526\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0152 - accuracy: 0.9941 - val_loss: 0.8860 - val_accuracy: 0.7579\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0276 - accuracy: 0.9858 - val_loss: 0.3325 - val_accuracy: 0.8316\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 2.2029 - val_accuracy: 0.6842\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 16s 223ms/step - loss: 0.0282 - accuracy: 0.9835 - val_loss: 3.1515 - val_accuracy: 0.3684\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 16s 226ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.1581 - val_accuracy: 0.9579\n",
      "Epoch 29/100\n",
      "63/71 [=========================>....] - ETA: 1s - loss: 0.0153 - accuracy: 0.9934"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5492/3579353673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Training for fold {fold_no} ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         history = model.fit(inputs[train], targets[train], \n\u001b[0m\u001b[0;32m     40\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    for train, test in kfold.split(X_train, y_train):\n",
    "        print(train.shape, test.shape)\n",
    "        \n",
    "        np.savetxt('E:/Result/ver.3.22/MTF/train_/' + f'train_{fold_no}.csv', train, delimiter=\",\")\n",
    "        np.savetxt('E:/Result/ver.3.22/MTF/test_/' + f'test_{fold_no}.csv', test, delimiter=\",\")\n",
    "\n",
    "        input = Input(shape=(300, 300, 2))\n",
    "        model = DenseNet121(input_tensor=input, include_top=False, weights=None, pooling='avg')\n",
    "        \n",
    "        x = model.output\n",
    "\n",
    "        x = Dense(3, activation='softmax', name='softmax', kernel_initializer='he_normal')(x)\n",
    "        model = Model(model.input, x)\n",
    "\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.SGD(lr=0.01, decay=1e-3, momentum=0.9, nesterov=True)\n",
    "        #optimizer = optimizers.Adam(lr=0.001)\n",
    "        \n",
    "        callbacks_list = [LearningRateSchedule([20,40])]\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        \n",
    "        history = model.fit(inputs[train], targets[train], \n",
    "                            batch_size=12, \n",
    "                            epochs=100, \n",
    "                            verbose=1,\n",
    "                            validation_data=(inputs[test], targets[test]),\n",
    "                            callbacks = tensorboard_callback) #  Validation set  ?\n",
    "        \n",
    "        scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "        print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "        \n",
    "        model.save('E:/Result/ver.3.22/MTF/weight_/' + f'MTF_{fold_no}.h5',fold_no)\n",
    "        \n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training','validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training','validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c7ec7915fb6663623914b2919607c696d31d8503b403c6d54bcb30c0bb224a7"
  },
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
